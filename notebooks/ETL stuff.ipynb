{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dateutil.parser\n",
    "import itertools\n",
    "import logging\n",
    "import pickle\n",
    "import math\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import pymongo\n",
    "import moves as mvs\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client.carbon_calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile = db.users.find_one({'userId': 32734778124657154})\n",
    "moves = mvs.MovesClient(access_token=profile['user']['access_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def existing_dates_(profile, record_type):\n",
    "    \"\"\" Finds the earliest update for a moves record. \"\"\"\n",
    "    docs = db.moves2.find({\n",
    "        'record_type': record_type,\n",
    "        'userId': profile['userId']\n",
    "        }, {'date': 1})\n",
    "    dates = [doc['date'].date() for doc in docs]\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def service_daterange(start_date):\n",
    "    \"\"\" Creates a list of datatime date objects from starting with\n",
    "    the date the person joined Moves to today.\n",
    "    \"\"\"\n",
    "    base_date = dateutil.parser.parse(start_date)\n",
    "    today = datetime.datetime.today()\n",
    "    numdays = (today - base_date).days\n",
    "    dates = [(today - datetime.timedelta(days=x)).date()\n",
    "                for x in range(0, numdays)]\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_dates(service_dates, existing_dates):\n",
    "    \"\"\" Returns a list of dates that haven't been fetched \"\"\"\n",
    "    return [date for date in service_dates if date not in existing_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_resource(resource, date, update_since=None):\n",
    "    \"\"\" Fetches a user's Moves summary for a given date range\n",
    "\n",
    "    Args:\n",
    "        resource: String of the moves resource to fetch.\n",
    "        start_date: String of the start date.\n",
    "        end_date: String of the end date.\n",
    "\n",
    "    Returns:\n",
    "        resources: List of resouce dicts from the Moves API\n",
    "\n",
    "    Raises:\n",
    "        ValueError: resource requested is not a moves resource.\n",
    "    \"\"\"\n",
    "    if resource not in ['summary', 'activities', 'places', 'storyline']:\n",
    "        raise ValueError('Invalid Moves resource.')\n",
    "\n",
    "    rsrc_path = \"user/{}/daily/{}?\".format(resource, date)\n",
    "\n",
    "    if resource == 'storyline':\n",
    "        rsrc_path = \"%s&trackPoints=true\" % rsrc_path\n",
    "\n",
    "    if update_since:\n",
    "        rsrc_path = \"%s&updateSince>T%sZ\" % (rsrc_path, update_since)\n",
    "\n",
    "    try:\n",
    "        resources = moves.api(rsrc_path, 'GET').json()\n",
    "    except Exception, exception:\n",
    "        logging.error(exception.message)\n",
    "        raise\n",
    "\n",
    "    return resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_resource(resource, record_type, profile):\n",
    "    \"\"\" Adds metadata to a move source record. \"\"\"\n",
    "    date_datetime = dateutil.parser.parse(resource['date'])\n",
    "\n",
    "    if resource.has_key('lastUpdate'):\n",
    "        update_datetime = dateutil.parser.parse(resource['lastUpdate'])\n",
    "    else:\n",
    "        update_datetime = date_datetime\n",
    "\n",
    "    transformed = {\n",
    "        'userId': profile['userId'],\n",
    "        'record_type': record_type,\n",
    "        'last_update': update_datetime,\n",
    "        'date': date_datetime,\n",
    "        'data': resource\n",
    "    }\n",
    "\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_resources(resources, record_type, profile):\n",
    "    \"\"\" Adds some metadata to raw Moves resources. \"\"\"\n",
    "    for resource in resources:\n",
    "        yield transform_resource(resource, record_type, profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_resources(transformed_resources):\n",
    "    \"\"\" Inserts a collection of transformed resources into\n",
    "    the moves staging database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res = db.moves2.insert(transformed_resources)\n",
    "    except pymongo.errors.BulkWriteError, results:\n",
    "        res = db.moves2.remove(results)\n",
    "        logging.error('BulkWriteError')\n",
    "    except Exception, exception:\n",
    "        logging.error(exception.message)\n",
    "        res = None\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fetch_resources(resource_type, missing_dates):\n",
    "    resources = []\n",
    "    for date in missing_dates[:30]:\n",
    "        resource = fetch_resource(resource_type, date)\n",
    "        resources.append(resource[0])\n",
    "    return resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_segments(storylines):\n",
    "    segments = [s['data']['segments'] for s in storylines \n",
    "                if s['data']['segments']]\n",
    "    return itertools.chain(*segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_activities(segments):\n",
    "    activities = [s['activities'] for s in segments \n",
    "                  if s.has_key('activities')]\n",
    "    return itertools.chain(*activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['subway', 'bus', 'car', 'airplane']\n",
    "model = pickle.load(open('../models/gradient_boosting.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subways_entrances = db.subway_entrances.find_one()\n",
    "features = subways_entrances['features']\n",
    "station_points = [p['geometry']['coordinates'] for p in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# labels[model.predict(create_features(transports[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_transport_type(transport, model):\n",
    "    X = create_features(transport)\n",
    "    pred = model.predict(X)\n",
    "    return labels[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_transport_types(transports, model):\n",
    "    X = np.array([create_features(t) for t in transports])\n",
    "    preds = model.predict(X)\n",
    "    return [labels[pred] for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_features(transport):\n",
    "#     start_time = dateutil.parser.parse(transport['startTime'])\n",
    "#     end_time = dateutil.parser.parse(transport['endTime'])\n",
    "#     fp = transport['trackPoints'][0]\n",
    "#     lp = transport['trackPoints'][-1]\n",
    "#     return {\n",
    "#         'distance': transport['distance'], \n",
    "#         'duration': transport['duration'], \n",
    "#         'startTimeSec': datetime_to_seconds(start_time),\n",
    "#         'endTimeSec': datetime_to_seconds(end_time), \n",
    "#         'startHour': start_time.hour, \n",
    "#         'trackpointCount': len(transport['trackPoints']),\n",
    "#         'closestSubwayEntrance': compute_total_distance([fp['lon'], fp['lat']], [lp['lon'], lp['lat']]),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_features(transport):\n",
    "    start_time = dateutil.parser.parse(transport['startTime'])\n",
    "    end_time = dateutil.parser.parse(transport['endTime'])\n",
    "    fp = transport['trackPoints'][0]\n",
    "    lp = transport['trackPoints'][-1]\n",
    "    feats = [\n",
    "        transport['distance'], \n",
    "        transport['duration'], \n",
    "        datetime_to_seconds(start_time),\n",
    "        datetime_to_seconds(end_time), \n",
    "        start_time.hour, \n",
    "        len(transport['trackPoints']),\n",
    "        compute_total_distance([fp['lon'], fp['lat']], [lp['lon'], lp['lat']]),\n",
    "    ]\n",
    "    return np.array(feats).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetime_to_seconds(dt):\n",
    "    return (dt.hour * 3600) + (dt.minute * 60) + dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_min_distance(lat_lng):\n",
    "    distances = [distance_on_unit_sphere(lat_lng[1], lat_lng[0], \n",
    "                    point[1], point[0]) for point in station_points] \n",
    "    return min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_total_distance(first_point, last_point):\n",
    "    start = compute_min_distance(first_point)\n",
    "    end = compute_min_distance(last_point)\n",
    "    \n",
    "    return start + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_on_unit_sphere(lat1, long1, lat2, long2):\n",
    "    # Convert latitude and longitude to \n",
    "    # spherical coordinates in radians.\n",
    "    degrees_to_radians = math.pi/180.0\n",
    "        \n",
    "    # phi = 90 - latitude\n",
    "    phi1 = (90.0 - lat1)*degrees_to_radians\n",
    "    phi2 = (90.0 - lat2)*degrees_to_radians\n",
    "        \n",
    "    # theta = longitude\n",
    "    theta1 = long1*degrees_to_radians\n",
    "    theta2 = long2*degrees_to_radians\n",
    "        \n",
    "    # Compute spherical distance from spherical coordinates.\n",
    "        \n",
    "    # For two locations in spherical coordinates \n",
    "    # (1, theta, phi) and (1, theta, phi)\n",
    "    # cosine( arc length ) = \n",
    "    #    sin phi sin phi' cos(theta-theta') + cos phi cos phi'\n",
    "    # distance = rho * arc length\n",
    "    \n",
    "    cos = (math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2) + \n",
    "           math.cos(phi1)*math.cos(phi2))\n",
    "    arc = math.acos(cos)\n",
    "\n",
    "    # Remember to multiply arc by the radius of the earth \n",
    "    # in your favorite set of units to get length.\n",
    "    earth_rad_miles = 3963.1676\n",
    "    earth_rad_feet = earth_rad_miles\n",
    "    \n",
    "    return arc * earth_rad_feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_resources = list(transform_resources(resources, 'storyline', profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_carbon(transport):\n",
    "    time.sleep(.05)\n",
    "    kgs = compute_carbon_kg(transports_with_type[30])\n",
    "    transport['carbon'] = kgs\n",
    "    return transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_prediction(transport, prediction):\n",
    "    transport['type'] = prediction\n",
    "    return transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEY = '20f32c9fad4aebc9998f8ce569bdc358'\n",
    "BASE = 'http://impact.brighterplanet.com/' \n",
    "TYPES = {\n",
    " 'car': 'automobile_trips.json',\n",
    " 'subway': 'rail_trips.json?class=commuter',\n",
    " 'airplane': 'flights.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_carbon_kg(transport):\n",
    "    url = BASE + TYPES[transport['type']]\n",
    "    params = {\n",
    "        'distance': transport['distance'],\n",
    "        'key': KEY\n",
    "    }\n",
    "    res = requests.get(url, params=params).json()\n",
    "    kgs = res['decisions']['carbon']['object']['value']\n",
    "    \n",
    "    return kgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 34, 36, 54, 84, 88, 96, 121]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ix for ix, p in enumerate(preds) if p != 'subway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "membership_dates = service_daterange(profile['profile']['firstDate'])\n",
    "existing_dates = existing_dates_(profile, 'storyline')\n",
    "non_existing_dates = missing_dates(membership_dates, existing_dates)\n",
    "resources = fetch_resources('storyline', non_existing_dates)\n",
    "transformed_resources = list(transform_resources(resources, 'storyline', profile))\n",
    "segments = list(extract_segments(transformed_resources))\n",
    "activities = list(extract_activities(segments))\n",
    "transports = [a for a in activities if a['activity'] == 'transport']\n",
    "preds = [predict_transport_type(transport, model) for transport in transports]\n",
    "transports_with_type = [add_prediction(t, preds[ix]) for ix, t in enumerate(transports)]\n",
    "transports_with_carbon = [add_carbon(t) for t in transports_with_type]\n",
    "insert_resources(transports_with_carbon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'activity': u'transport',\n",
       " 'carbon': 2172.080498999573,\n",
       " u'distance': 468.0,\n",
       " u'duration': 450.0,\n",
       " u'endTime': u'20160414T105904-0400',\n",
       " u'group': u'transport',\n",
       " u'manual': False,\n",
       " u'startTime': u'20160414T105134-0400',\n",
       " u'trackPoints': [{u'lat': 40.766929,\n",
       "   u'lon': -73.98125,\n",
       "   u'time': u'20160414T105134-0400'},\n",
       "  {u'lat': 40.7634, u'lon': -73.982542, u'time': u'20160414T105848-0400'},\n",
       "  {u'lat': 40.7634, u'lon': -73.982542, u'time': u'20160414T105904-0400'}],\n",
       " 'type': 'subway'}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transports_with_carbon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
