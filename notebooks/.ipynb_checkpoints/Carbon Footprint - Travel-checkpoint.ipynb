{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Travel Carbon Footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client.carbon_calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Transport for Raw Moves Storylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_moves = list(db.moves.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_segments = itertools.chain(*[mv['data']['segments'] for mv in raw_moves if mv['data']['segments']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_activities = list(itertools.chain(*[seg['activities'] for seg in raw_segments if seg.has_key('activities')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_transports = [process_transport(act) for act in raw_activities if act['activity'] == 'transport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert the non-existant transports\n",
    "# for transport in raw_transports:\n",
    "#     existing = db.moves_transport.find_one({'endTime': transport['endTime']})\n",
    "#     if not existing:\n",
    "#         db.moves_transport.insert(transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set verified status to False\n",
    "# db.moves_transport.update(\n",
    "#     {'verified': {'$ne': False}},\n",
    "#     {'$set': {'verified': False}},\n",
    "#     multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_transport(trans):\n",
    "    return {\n",
    "        'distance': trans['distance'],\n",
    "        'duration': trans['duration'], \n",
    "        'endTime': trans['endTime'], \n",
    "        'startTime': trans['startTime'],\n",
    "        'trackPoints': trans['trackPoints'],\n",
    "        'type': None,\n",
    "        'verified': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mis en place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transports = db.moves_transport.find()\n",
    "labeled_transport = db.moves_transport.find({'type': {'$ne': None}})\n",
    "subways_entrances = db.subway_entrances.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldf = pd.DataFrame(list(labeled_transport))\n",
    "# ldf = pd.DataFrame(list(transports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add first and last point\n",
    "ldf['firstPoint'] = ldf.trackPoints.apply(lambda points: [points[0]['lon'], points[0]['lat']])\n",
    "ldf['lastPoint'] = ldf.trackPoints.apply(lambda points: [points[-1]['lon'], points[-1]['lat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add start and end times\n",
    "ldf['endTime'] = ldf.endTime.apply(pd.to_datetime)\n",
    "ldf['startTime'] = ldf.startTime.apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add trackpoint count\n",
    "ldf['trackpointCount'] = ldf.trackPoints.apply(lambda v: len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldf['startHour'] = ldf.startTime.apply(lambda d: d.hour)\n",
    "ldf['endHour'] = ldf.endTime.apply(lambda d: d.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add start and end time in seconds\n",
    "ldf['startTimeSec'] = ldf.startTime.apply(lambda t: (t.hour * 3600) + (t.minute * 60) + t.second + (t.microsecond / 1000000.0))\n",
    "ldf['endTimeSec'] = ldf.endTime.apply(lambda t: (t.hour * 3600) + (t.minute * 60) + t.second + (t.microsecond / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add subway distance\n",
    "features = subways_entrances['features']\n",
    "station_points = [p['geometry']['coordinates'] for p in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: run the helper functions at the bottom of the notebook first\n",
    "ldf['closestSubwayEntrance'] = ldf.apply(compute_total_distance, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_cols = [\n",
    "    'distance', 'duration', \n",
    "    'startTimeSec', 'endTimeSec', \n",
    "    'startHour', 'trackpointCount',\n",
    "    'closestSubwayEntrance', 'type', '_id'\n",
    "]\n",
    "df = ldf.ix[:, training_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the values\n",
    "# df[training_cols[:-2]] -= df[training_cols[:-2]].min()\n",
    "# df[training_cols[:-2]] /= df[training_cols[:-2]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = df.columns[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only take the records that are common vehicles\n",
    "data = df[df.type.isin(['subway', 'car', 'airplane', 'bus'])]\n",
    "X = data[features]\n",
    "y, labels = pd.factorize(data['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random forest\n",
    "# clf = RandomForestClassifier(n_jobs=-1, n_estimators=300)\n",
    "# clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=300)\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "# clf = SVC(kernel='rbf', C = 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the thing for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = df[features]\n",
    "# preds = labels[clf.predict(X)]\n",
    "# df.insert(8, 'pred', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for row in df.to_dict(orient='records'):\n",
    "#     db.moves_transport.update(\n",
    "#         {'_id': row['_id']},\n",
    "#         {'$set': {'pred': row['pred']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the model\n",
    "# model = 'gradient_boosting.p'\n",
    "# pickle.dump(clf, open('../models/' + model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>airplane</th>\n",
       "      <th>bus</th>\n",
       "      <th>car</th>\n",
       "      <th>subway</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subway</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds     airplane  bus  car  subway\n",
       "actual                              \n",
       "airplane         3    0    0       0\n",
       "bus              0    3    2       2\n",
       "car              0    2   51      18\n",
       "subway           0    0    7     219"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    labels[y_test], labels[preds], \n",
    "    rownames=['actual'], colnames=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the missclassified results\n",
    "tdf = data.ix[X_test.index]\n",
    "tdf.insert(8, 'pred', labels[preds])\n",
    "misclassified = tdf[tdf.pred != tdf.type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# misclassified = pd.concat([misclassified, data['_id']], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update the misclassified's preds\n",
    "for pred in misclassified.to_dict(orient='records'):\n",
    "    db.moves_transport.update(\n",
    "        {'_id': pred['_id']},\n",
    "        {'$set': {'pred': pred['pred']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dump the ids of the misclassified for use in diagnosis\n",
    "import pickle\n",
    "pickle.dump(list(misclassified._id), open('../../moves-labeler/misclassified.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94695194031231045"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=5, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30926549,  0.12236559,  0.05202291,  0.04361547,  0.01018678,\n",
       "        0.20556723,  0.20447653])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'distance', u'duration', u'startTimeSec', u'endTimeSec', u'startHour',\n",
       "       u'trackpointCount', u'closestSubwayEntrance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# ax.scatter(X, Y, Z, c=pd.factorize(test['type'])[0], cmap='jet')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key = '20f32c9fad4aebc9998f8ce569bdc358'\n",
    "base = 'http://impact.brighterplanet.com/' \n",
    "type_ = 'automobile_trips.json'\n",
    "url = base + type_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_carbon_kg(distance):\n",
    "    time.sleep(.1)\n",
    "    params = {\n",
    "        'distance': distance,\n",
    "        'key': key\n",
    "    }\n",
    "    res = requests.get(url, params=params).json()\n",
    "    kgs = res['decisions']['carbon']['object']['value']\n",
    "    \n",
    "    return kgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kilometerize(moves_steps):\n",
    "    return (moves_steps * 3.25) / 3280.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driving = ldf[ldf.type=='car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "driving['km'] = driving.distance.apply(kilometerize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driving_test = driving.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "driving_test['carbon_kg'] = driving_test.km.apply(compute_carbon_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21    1.501059\n",
       "30    1.371338\n",
       "31    2.520596\n",
       "32    2.722650\n",
       "33    1.937747\n",
       "Name: carbon_kg, dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_test.carbon_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Distance from Subways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_min_distance(lat_lng):\n",
    "    distances = [distance_on_unit_sphere(lat_lng[1], lat_lng[0], \n",
    "                    point[1], point[0]) for point in station_points] \n",
    "    return min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_total_distance(row):\n",
    "    start = compute_min_distance(row['firstPoint'])\n",
    "    end = compute_min_distance(row['lastPoint'])\n",
    "    \n",
    "    return start + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distance_on_unit_sphere(lat1, long1, lat2, long2):\n",
    "    # Convert latitude and longitude to \n",
    "    # spherical coordinates in radians.\n",
    "    degrees_to_radians = math.pi/180.0\n",
    "        \n",
    "    # phi = 90 - latitude\n",
    "    phi1 = (90.0 - lat1)*degrees_to_radians\n",
    "    phi2 = (90.0 - lat2)*degrees_to_radians\n",
    "        \n",
    "    # theta = longitude\n",
    "    theta1 = long1*degrees_to_radians\n",
    "    theta2 = long2*degrees_to_radians\n",
    "        \n",
    "    # Compute spherical distance from spherical coordinates.\n",
    "        \n",
    "    # For two locations in spherical coordinates \n",
    "    # (1, theta, phi) and (1, theta, phi)\n",
    "    # cosine( arc length ) = \n",
    "    #    sin phi sin phi' cos(theta-theta') + cos phi cos phi'\n",
    "    # distance = rho * arc length\n",
    "    \n",
    "    cos = (math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2) + \n",
    "           math.cos(phi1)*math.cos(phi2))\n",
    "    arc = math.acos(cos)\n",
    "\n",
    "    # Remember to multiply arc by the radius of the earth \n",
    "    # in your favorite set of units to get length.\n",
    "    earth_rad_miles = 3963.1676\n",
    "    earth_rad_feet = earth_rad_miles\n",
    "    \n",
    "    return arc * earth_rad_feet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "    'distance', 'duration', 'startHour', 'endHour',\n",
    "    'trackpointCount'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(ldf[target_cols].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"x\": X[:, 0], \"y\": X[:, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.lmplot('x', 'y', data=df, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_start_end_diff(target, comparison):\n",
    "    \n",
    "    start_dist = distance_on_unit_sphere(\n",
    "        target['firstPoint'][1], target['firstPoint'][0],\n",
    "        comparison['firstPoint'][1], comparison['firstPoint'][0])\n",
    "    \n",
    "    end_dist = distance_on_unit_sphere(\n",
    "        target['lastPoint'][1], target['lastPoint'][0],\n",
    "        comparison['lastPoint'][1], comparison['lastPoint'][0])\n",
    "    return start_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = ldf.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# diffs = []\n",
    "# for ixx, x in enumerate(records):\n",
    "#     diff = []\n",
    "#     for ixy, y in enumerate(records):\n",
    "#         try:\n",
    "#             if ixx != ixy:\n",
    "#                 dist = compute_start_end_diff(x, y)\n",
    "#             else:\n",
    "#                 dist = 0\n",
    "#         except:\n",
    "#             print ixx\n",
    "#             print ixy\n",
    "#             dist = np.nan\n",
    "#         diff.append(dist)\n",
    "#     diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diffdf.columns = ldf._id.astype(str) #.apply(lambda s: s[-5:])\n",
    "diffdf.index = ldf._id.astype(str) # .apply(lambda s: s[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
